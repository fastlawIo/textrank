{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorrect-wyoming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vadim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import clip\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "\n",
    "model_name_or_path = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).cuda()\n",
    "\n",
    "def ppl(context: str, continuation: str) -> float:\n",
    "    t = tokenizer(text=[context], text_pair=[continuation], return_token_type_ids=True, return_tensors=\"pt\")\n",
    "    context_mask = ~t.token_type_ids.bool()\n",
    "\n",
    "    lossess = []\n",
    "    while not context_mask.all():\n",
    "        input_ids = t.input_ids\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[context_mask] = -100\n",
    "        with torch.no_grad():\n",
    "            loss = model(input_ids.to('cuda'), labels=target_ids.to('cuda')).loss\n",
    "        lossess.append(loss)\n",
    "\n",
    "        context_mask = context_mask.roll(1)\n",
    "        context_mask[:, 0] = True\n",
    "    \n",
    "    return torch.exp(torch.stack(lossess).sum() / context_mask.size(1)).item()\n",
    "\n",
    "def cross_ppl(txts: List[str]) -> np.array:\n",
    "    res = np.zeros((len(txts), len(txts)))\n",
    "    for i, context in enumerate(txts):\n",
    "        for j, continuation in enumerate(txts):\n",
    "            res[i, j] = ppl(context, continuation)\n",
    "    return torch.tensor(res)\n",
    "\n",
    "#model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "#model = SentenceTransformer('paraphrase-albert-small-v2')\n",
    "#model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
    "#model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "#model = SentenceTransformer('sentence-transformers/gtr-t5-xxl')\n",
    "#_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#_encoder, _img_transform = clip.load('ViT-B/32', device=_device, jit=False)\n",
    "#_encoder.eval()\n",
    "\n",
    "#def calc_adjacency(nodes: List[str]) -> torch.tensor:\n",
    "#    trankated = [txt[0:70] for txt in nodes]\n",
    "#    tokens = clip.tokenize(trankated).to(_device)\n",
    "\n",
    "#    with torch.no_grad():\n",
    "#        vecs = _encoder.encode_text(tokens).cpu().type(torch.DoubleTensor)\n",
    "        #vecs = vecs / vecs.norm(dim=1, p=2).unsqueeze(1)\n",
    "        #vecs = vecs.cpu().numpy().astype(np.float32)\n",
    "    \n",
    "    #vecs = torch.tensor(model.encode(nodes))\n",
    "#    dists = torch.cdist(vecs, vecs)\n",
    "#    sims = (dists.max(dim=0)[0] - dists)\n",
    "    #sims = vecs.matmul(vecs.t())\n",
    "#    return sims / sims.sum(dim=0)\n",
    "\n",
    "def calc_adjacency(nodes: List[str]) -> torch.tensor:\n",
    "    #vecs = torch.tensor(model.encode(nodes))\n",
    "    #dists = torch.cdist(vecs, vecs)\n",
    "    #sims = (dists.max(dim=0)[0] - dists)\n",
    "    #sims = vecs.matmul(vecs.t())\n",
    "    \n",
    "    dists = cross_ppl(nodes)\n",
    "    sims = (dists.max(dim=0)[0] - dists)\n",
    "    return sims / sims.sum(dim=0)\n",
    "\n",
    "def summorize(text: str) -> List[Tuple[str, int]]:\n",
    "    nodes = sent_tokenize(text)\n",
    "    adjacency_matrix = calc_adjacency(nodes)\n",
    "    qd = torch.linalg.eig(calc_adjacency(nodes))#.eigenvectors[0].real.argsort()\n",
    "    #print(qd.eigenvalues)\n",
    "    ranks = qd.eigenvectors[0].real.softmax(dim=0).numpy()\n",
    "    return ranks, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "arbitrary-garbage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1275, 0.1044, 0.1075, 0.1235, 0.1040, 0.1038, 0.1019, 0.1058, 0.0900,\n",
       "         0.1007],\n",
       "        [0.1151, 0.1358, 0.1156, 0.1409, 0.1153, 0.1134, 0.1121, 0.1134, 0.1176,\n",
       "         0.1155],\n",
       "        [0.1121, 0.1157, 0.1320, 0.1299, 0.1141, 0.1072, 0.1124, 0.1128, 0.1190,\n",
       "         0.1157],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.1138, 0.1173, 0.1137, 0.1315, 0.1400, 0.1099, 0.1126, 0.1107, 0.1114,\n",
       "         0.1092],\n",
       "        [0.0945, 0.0910, 0.0898, 0.0395, 0.0891, 0.1283, 0.0974, 0.0850, 0.0748,\n",
       "         0.0888],\n",
       "        [0.0997, 0.0953, 0.0966, 0.0362, 0.0899, 0.1029, 0.1237, 0.0942, 0.0838,\n",
       "         0.0976],\n",
       "        [0.1039, 0.1008, 0.1056, 0.0901, 0.1034, 0.1013, 0.1069, 0.1383, 0.1012,\n",
       "         0.1048],\n",
       "        [0.1199, 0.1249, 0.1232, 0.1605, 0.1271, 0.1180, 0.1176, 0.1242, 0.1760,\n",
       "         0.1282],\n",
       "        [0.1135, 0.1148, 0.1161, 0.1479, 0.1171, 0.1153, 0.1153, 0.1156, 0.1261,\n",
       "         0.1395]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Я хочу рассказать о разработанном мной сервисе реферирования новостных текстов на английском, \n",
    "русском и немецком языках. Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем, \n",
    "кто занимается автоматической обработкой языка. \n",
    "Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и \n",
    "быстро принять решение о том, какая информация стоит дальнейшего рассмотрения. \n",
    "Как обстоит дело? С одной стороны, в процессе поиска аналогов я заметил интересную вещь — большинство найденных мною статей, сервисов, \n",
    "репозиториев и пр. датируются самое позднее 2012 годом. На Хабре есть статья на тему автоматического реферирования, опубликованная в 2011 году. \n",
    "В этом же году новостное реферирование было последний раз включено в список треков конференции TAC.\n",
    "С другой стороны, набирают популярность мобильные приложения, которые обрабатывают новостные потоки и представляют пользователю короткие рефераты на выбранные им темы. \n",
    "Яркий пример такой востребованности — относительно недавняя (2013 г.) покупка \n",
    "Google и Yahoo саммарайзеров-стартапов Wavii и Summly соответственно, а также наличие различных браузер-плагинов, реферирующих веб-страницы (Chrome, Mozilla).\n",
    "Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"\n",
    "\"\"\".replace('\\n', ' ')\n",
    "\n",
    "calc_adjacency(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "registered-enhancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.ppl(context: str, continuation: str) -> float>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-period",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-ozone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "israeli-valuable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Я хочу рассказать о разработанном мной сервисе реферирования новостных текстов на английском,  русском и немецком языках.',\n",
       " 'Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.',\n",
       " 'Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и  быстро принять решение о том, какая информация стоит дальнейшего рассмотрения.',\n",
       " 'Как обстоит дело?',\n",
       " 'С одной стороны, в процессе поиска аналогов я заметил интересную вещь — большинство найденных мною статей, сервисов,  репозиториев и пр. датируются самое позднее 2012 годом.',\n",
       " 'На Хабре есть статья на тему автоматического реферирования, опубликованная в 2011 году.',\n",
       " 'В этом же году новостное реферирование было последний раз включено в список треков конференции TAC.',\n",
       " 'С другой стороны, набирают популярность мобильные приложения, которые обрабатывают новостные потоки и представляют пользователю короткие рефераты на выбранные им темы.',\n",
       " 'Яркий пример такой востребованности — относительно недавняя (2013 г.) покупка  Google и Yahoo саммарайзеров-стартапов Wavii и Summly соответственно, а также наличие различных браузер-плагинов, реферирующих веб-страницы (Chrome, Mozilla).',\n",
       " 'Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = sent_tokenize(text, language=\"russian\")\n",
    "\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "structural-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Я хочу рассказать о разработанном мной сервисе реферирования новостных текстов на английском,  русском и немецком языках.\n",
      "\t---0.12: Как обстоит дело?\n",
      "\t---0.11: Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и  быстро принять решение о том, какая информация стоит дальнейшего рассмотрения.\n",
      "\t---0.11: С другой стороны, набирают популярность мобильные приложения, которые обрабатывают новостные потоки и представляют пользователю короткие рефераты на выбранные им темы.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.\n",
      "\t---0.14: Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.\n",
      "\t---0.12: Яркий пример такой востребованности — относительно недавняя (2013 г.) покупка  Google и Yahoo саммарайзеров-стартапов Wavii и Summly соответственно, а также наличие различных браузер-плагинов, реферирующих веб-страницы (Chrome, Mozilla).\n",
      "\t---0.12: Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и  быстро принять решение о том, какая информация стоит дальнейшего рассмотрения.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и  быстро принять решение о том, какая информация стоит дальнейшего рассмотрения.\n",
      "\t---0.13: Как обстоит дело?\n",
      "\t---0.12: Яркий пример такой востребованности — относительно недавняя (2013 г.) покупка  Google и Yahoo саммарайзеров-стартапов Wavii и Summly соответственно, а также наличие различных браузер-плагинов, реферирующих веб-страницы (Chrome, Mozilla).\n",
      "\t---0.12: Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "Как обстоит дело?\n",
      "\t---0.0: Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.\n",
      "\t---0.0: Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и  быстро принять решение о том, какая информация стоит дальнейшего рассмотрения.\n",
      "\t---0.0: Как обстоит дело?\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "С одной стороны, в процессе поиска аналогов я заметил интересную вещь — большинство найденных мною статей, сервисов,  репозиториев и пр. датируются самое позднее 2012 годом.\n",
      "\t---0.13: Как обстоит дело?\n",
      "\t---0.12: Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.\n",
      "\t---0.11:  Я хочу рассказать о разработанном мной сервисе реферирования новостных текстов на английском,  русском и немецком языках.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "На Хабре есть статья на тему автоматического реферирования, опубликованная в 2011 году.\n",
      "\t---0.1: В этом же году новостное реферирование было последний раз включено в список треков конференции TAC.\n",
      "\t---0.09:  Я хочу рассказать о разработанном мной сервисе реферирования новостных текстов на английском,  русском и немецком языках.\n",
      "\t---0.09: Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "В этом же году новостное реферирование было последний раз включено в список треков конференции TAC.\n",
      "\t---0.1: На Хабре есть статья на тему автоматического реферирования, опубликованная в 2011 году.\n",
      "\t---0.1:  Я хочу рассказать о разработанном мной сервисе реферирования новостных текстов на английском,  русском и немецком языках.\n",
      "\t---0.1: Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "С другой стороны, набирают популярность мобильные приложения, которые обрабатывают новостные потоки и представляют пользователю короткие рефераты на выбранные им темы.\n",
      "\t---0.11: В этом же году новостное реферирование было последний раз включено в список треков конференции TAC.\n",
      "\t---0.11: Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и  быстро принять решение о том, какая информация стоит дальнейшего рассмотрения.\n",
      "\t---0.1: Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "Яркий пример такой востребованности — относительно недавняя (2013 г.) покупка  Google и Yahoo саммарайзеров-стартапов Wavii и Summly соответственно, а также наличие различных браузер-плагинов, реферирующих веб-страницы (Chrome, Mozilla).\n",
      "\t---0.16: Как обстоит дело?\n",
      "\t---0.13: Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"\n",
      "\t---0.13: С одной стороны, в процессе поиска аналогов я заметил интересную вещь — большинство найденных мною статей, сервисов,  репозиториев и пр. датируются самое позднее 2012 годом.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"\n",
      "\t---0.14: Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"\n",
      "\t---0.13: Яркий пример такой востребованности — относительно недавняя (2013 г.) покупка  Google и Yahoo саммарайзеров-стартапов Wavii и Summly соответственно, а также наличие различных браузер-плагинов, реферирующих веб-страницы (Chrome, Mozilla).\n",
      "\t---0.12: С одной стороны, в процессе поиска аналогов я заметил интересную вещь — большинство найденных мною статей, сервисов,  репозиториев и пр. датируются самое позднее 2012 годом.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for txt, sims in zip(nodes, calc_adjacency(nodes)):\n",
    "    print(txt)\n",
    "    for i in sims.argsort(descending=True)[1:4]:\n",
    "        print(f'\\t---{round(sims[i].item(), 2)}: {nodes[i]}')\n",
    "    print('\\n\\n------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-masters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "handmade-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.13107621351784757,\n",
       "  'С другой стороны, набирают популярность мобильные приложения, которые обрабатывают новостные потоки и представляют пользователю короткие рефераты на выбранные им темы.'),\n",
       " (0.12555980912459597,\n",
       "  'Яркий пример такой востребованности — относительно недавняя (2013 г.)'),\n",
       " (0.12242771916711423,\n",
       "  'покупка  Google и Yahoo саммарайзеров-стартапов Wavii и Summly соответственно, а также наличие различных браузер-плагинов, реферирующих веб-страницы (Chrome, Mozilla).'),\n",
       " (0.10475606597601432,\n",
       "  ' Я хочу рассказать о разработанном мной сервисе реферирования новостных текстов на английском,  русском и немецком языках.'),\n",
       " (0.07634288305813966,\n",
       "  'Беглое же тестирование бесплатных он-лайн сервисов реферирования показывает, что большинство из них работает схоже, выдавая одинаково средние результаты, среди которых, пожалуй, в лучшую сторону выделяется Autosummarizer.\"'),\n",
       " (0.0752978496336471,\n",
       "  'Системы автоматического реферирования (резюмирования) (САР) — тема довольно специфическая и будет интересна в основном тем,  кто занимается автоматической обработкой языка.'),\n",
       " (0.06511161527568968, 'Как обстоит дело?'),\n",
       " (0.06373663084049645, 'датируются самое позднее 2012 годом.'),\n",
       " (0.06373663084049645,\n",
       "  'С одной стороны, в процессе поиска аналогов я заметил интересную вещь — большинство найденных мною статей, сервисов,  репозиториев и пр.'),\n",
       " (0.05876072559740847,\n",
       "  'В этом же году новостное реферирование было последний раз включено в список треков конференции TAC.'),\n",
       " (0.05876072559740847,\n",
       "  'На Хабре есть статья на тему автоматического реферирования, опубликованная в 2011 году.'),\n",
       " (0.054433131371141516,\n",
       "  'Хотя идеально исполненный саммарайзер мог бы стать полезным помощником в сферах, где необходимо преодолеть информационный перегруз и  быстро принять решение о том, какая информация стоит дальнейшего рассмотрения.')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, n = summorize(text)\n",
    "\n",
    "[ (r[i], n[i]) for i in np.flip(r.argsort())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-handy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-tradition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-needle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "behavioral-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppl(context: str, continuation: str) -> float:\n",
    "    t = tokenizer(text=[context], text_pair=[continuation], return_token_type_ids=True, return_tensors=\"pt\")\n",
    "    context_mask = ~t.token_type_ids.bool()\n",
    "\n",
    "    lossess = []\n",
    "    while not context_mask.all():\n",
    "        input_ids = t.input_ids\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[context_mask] = -100\n",
    "        with torch.no_grad():\n",
    "            loss = model(input_ids.to('cuda'), labels=target_ids.to('cuda')).loss\n",
    "        lossess.append(loss)\n",
    "\n",
    "        context_mask = context_mask.roll(1)\n",
    "        context_mask[:, 0] = True\n",
    "    \n",
    "    return torch.exp(torch.stack(lossess).sum() / context_mask.size(1)).item()\n",
    "\n",
    "def cross_ppl(txts: List[str]) -> np.array:\n",
    "    res = np.zeros((len(txts), len(txts)))\n",
    "    for i, context in enumerate(txts):\n",
    "        for j, continuation in enumerate(txts):\n",
    "            res[i, j] = ppl(context, continuation)\n",
    "    return torch.tensor(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "european-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   21,   491,   816,    23, 50257],\n",
       "        [   24,    24,  1061,  1286,  1409]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['1 2 3', '4'] \n",
    "continuation = ['3', '4 5 6 7']\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "t = tokenizer(text=context, text_pair=continuation, padding=True, return_token_type_ids=True, return_tensors=\"pt\")\n",
    "context_mask = ~t.token_type_ids.bool()\n",
    "\n",
    "#lossess = []\n",
    "#while not context_mask.all():\n",
    "input_ids = t.input_ids\n",
    "target_ids = input_ids.clone()\n",
    "target_ids[context_mask] = -100\n",
    "#    with torch.no_grad():\n",
    "#        loss = model(input_ids.to('cuda'), labels=target_ids.to('cuda')).loss\n",
    "#    lossess.append(loss)\n",
    "\n",
    "#    context_mask = context_mask.roll(1)\n",
    "#        context_mask[:, 0] = True\n",
    "\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "recent-agenda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  True, False],\n",
       "        [False,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.attention_mask.bool() & t.token_type_ids.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "union-carpet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizer(text=context, text_pair=continuation, padding=True, return_token_type_ids=True, return_tensors=\"pt\")\n",
    "t.attention_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
